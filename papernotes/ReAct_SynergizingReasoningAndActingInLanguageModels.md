<!-- -->
<!-- chinese -->
# ReAct: Synergizing Reasoning and Acting in Language Models
协同推理与行动

尽管大语言模型（LLMs）在语言理解和交互式决策任务中已展现出卓越性能，但其**推理能力**（例如思维链提示，chain-of-thought prompting）与**行动能力**（例如生成行动计划）的研究长期以来基本是割裂进行的。本文提出一种名为 ReAct 的方法，让 LLM 交替生成推理轨迹与任务相关的具体动作，从而实现二者的深度协同

推理轨迹帮助模型制定、跟踪并动态更新行动计划，同时处理异常情况；
具体动作则使模型能够与外部环境（如知识库或交互系统）交互，获取额外信息以支持推理。

compared to baseline 性能更优，而且生成的轨迹更易于人类理解，增强了可信度
在问答任务（HotpotQA）和事实验证任务（Fever）上，ReAct 通过调用一个简单的 Wikipedia API，有效缓解了传统思维链中常见的幻觉（hallucination）问题，并生成了类似人类的、可解释的任务解决过程。
在两个交互式决策基准（ALFWorld 和 WebShop）上，ReAct 仅凭1–2 个示例进行上下文学习（in-context learning），就分别以 34% 和 10% 的绝对成功率优势，超越了模仿学习与强化学习方法
[baseline 数据支持]


## introduction
人类智能的一个独特特征，是能够**无缝融合任务导向的行动与语言推理**（即“内心言语”，Alderson-Day & Fernyhough, 2015）。理论认为，这种能力在人类认知中扮演着关键角色：它支持自我调节与策略规划（Vygotsky, 1987；Luria, 1965；Fernyhough, 2010），并有助于维持工作记忆（Baddeley, 1992）。

在任意两个具体动作之间，我们可能会用语言进行推理
做了什么事/发生什么情况/需要额外信息/ -> 言语推理 ->行动

exp:
追踪进度：“现在所有食材都切好了，我该把水烧开了”；
处理异常或调整计划：“我没有盐了，那就用酱油和胡椒代替吧”；
意识到需要外部信息：“面团该怎么准备？我上网查一下”。

近期研究暗示，这种推理与行动的结合也可能应用于自主系统
但现在的CoT推理是一个静态黑箱：模型仅依赖其内部表征生成思维，未与外部世界建立联系，因此难以进行反应式推理或更新知识，容易导致事实幻觉（hallucination） 和推理过程中的错误传播（如图1(1b)所示）

![alt text](image.png)

另一方面，近期工作探索了使用预训练语言模型在交互环境中进行规划与行动（Ahnet al., 2022；Nakano et al., 2021；Yao et al., 2020；Huang et al., 2022a），重点是利用语言先验来预测动作。
除了这类与少量积木交互的简单具身任务外，尚无研究系统探索如何在通用任务求解中协同结合推理与行动，也未验证这种结合是否比单独使用推理或行动更具系统性优势。

在本文中，我们提出了 ReAct（Reason + Act）——一种通用范式，通过语言模型协同推理与行动，以解决多样化的语言推理与决策任务（见图1）。
ReAct 通过**提示 LLM 交替生成与任务相关的言语推理轨迹与具体动作**，使模型能够：

动态推理，以制定、维护并调整高层行动计划（推理以指导行动）；
与外部环境（如 Wikipedia），将新信息融入推理过程（行动以支持推理）。


我们对 ReAct 与当前最先进的基线方法在四个多样化的基准上进行了**实证评估**
问答任务（HotpotQA，Yang 等，2018）
事实验证（Fever，Thorne 等，2018）
文本游戏（ALFWorld，Shridhar 等，2020b）
网页导航（WebShop，Yao 等，2022）

HotpotQA/Fever 
整体表现最优的方案是 ReAct 与 CoT 的结合，因为它能在推理过程中同时利用模型的内部知识与从外部获取的信息。

ALFWorld/WebShop
仅使用一到两个示例（one- or two-shot），ReAct 就显著超越了那些使用 10³ 至 10⁵ 个任务实例训练的模仿学习或强化学习方法，在成功率上分别实现了 **34% 和 10%** 的绝对提升。

推理与行动的结合还显著增强了模型的可解释性、可信度与可诊断性
:区分模型所用信息是来自其内部知识还是外部环境,理解其动作背后的决策依据

**总结：本文的核心贡献如下：**
提出 ReAct：一种新颖的基于提示的范式，首次在语言模型中系统性地协同推理与行动，以解决通用任务；
广泛实验验证：在多个多样化基准上证明，ReAct 在少样本（few-shot） 设置下显著优于仅进行推理或仅生成动作的现有方法；
系统性消融分析：深入探究了在推理任务中引入行动的重要性，以及在交互式任务中引入推理的价值；
分析局限并探索改进路径：指出在 纯提示 范式下，ReAct 对复杂推理与行动行为的支持有限，并通过初步的微调实验表明，引入更多训练数据可进一步提升 ReAct 的能力。

## ReAct：协同推理与行动
智能体与环境交互以完成任务
ct = (o1,a1,...,ot-1,at-1,ot)
上下文  迄今为止的完整交互历史

当从上下文 ct 到动作 at 的映射高度隐式、且需要复杂推理时，学习该策略极具挑战性。

# Noun explanation && Extensive knowledge 
## 推理能力 & 行动能力




# 思考？


