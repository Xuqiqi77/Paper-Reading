<!-- -->
<!-- 应该说是技术报告 -->
# Effective context engineering for AI agents - anthropic
上下文是 AI 智能体的关键资源，但也是有限的。本文将探讨如何有效地筛选和管理驱动这些智能体的上下文。

上下文指的是在对大语言模型（LLM）进行采样时所包含的一组 token。

要考虑在任意给定时刻提供给 LLM 的整体状态，以及该状态可能引发的潜在行为

## 上下文工程 vs 提示工程
在 Anthropic，我们将上下文工程视为提示工程的自然演进。

提示工程指的是编写和组织大语言模型（LLM）指令以获得最佳输出的方法

而上下文工程则是指在 LLM 推理过程中，筛选并维护最优 token 集（即信息）的一整套策略——这不仅包括提示本身，**还涵盖所有可能被送入上下文窗口**的其他信息。

随着我们转向构建更强大的智能体——这些智能体需要在多轮推理和更长时间跨度中持续运行——我们就必须发展出管理整个上下文状态的策略，包括系统指令、工具、模型上下文协议（MCP）、外部数据、对话历史等

与编写提示这一离散任务不同，上下文工程是迭代性的：每次决定向模型传递哪些内容时，都会发生一次上下文筛选。

![alt text](image.png)

## 为何上下文工程对构建强大智能体至关重要？
在“大海捞针”（needle-in-a-haystack）类基准测试中，研究者发现了“上下文衰减”（context rot）现象

这种注意力稀缺源于 LLM 的架构约束。
transformer n的平方

虽然像位置编码插值（position encoding interpolation）等技术可以让模型通过适配原始训练上下文长度来处理更长序列，但代价是 token 位置理解的一定程度退化。这些因素共同造就了一种性能“渐变”而非“硬性断崖”：模型在长上下文中依然具备很强能力，但在信息检索和长程推理方面的精确度，相比短上下文场景仍会有所下降。

# Noun explanation && Extensive knowledge 




# 思考？
提示词工程
大海捞针，单一目标，流式输入，动态舍弃（在多目标上怎么办?）

